{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Matching & Entity Linking\n",
    "#### Step 1) Loading our extracted data!\n",
    "Here, we are repeating the last step of the first tutorial to create a data-frame containing the features that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flight</th>\n",
       "      <th>Location</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Boeing</td>\n",
       "      <td>November 10, 2008</td>\n",
       "      <td>Ryanair Flight 4102</td>\n",
       "      <td></td>\n",
       "      <td>November 10, 2008, Ryanair Flight 4102, a Boei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Airbus</td>\n",
       "      <td>January 30, 2000</td>\n",
       "      <td></td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>January 30, 2000, Kenya Airways Flight 431, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Merpati Nusantara Airlines</td>\n",
       "      <td>June 10, 2013</td>\n",
       "      <td>Flight 6517</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>June 10, 2013, Merpati Nusantara Airlines Flig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Airline               Date               Flight  \\\n",
       "980                       Boeing  November 10, 2008  Ryanair Flight 4102   \n",
       "843                       Airbus   January 30, 2000                        \n",
       "1076  Merpati Nusantara Airlines      June 10, 2013          Flight 6517   \n",
       "\n",
       "       Location                                               Text  \n",
       "980              November 10, 2008, Ryanair Flight 4102, a Boei...  \n",
       "843     Abidjan  January 30, 2000, Kenya Airways Flight 431, an...  \n",
       "1076  Indonesia  June 10, 2013, Merpati Nusantara Airlines Flig...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "incidents = []\n",
    "with open('./data/aviation_incidents_cleaned.txt') as myfile:\n",
    "    for line in myfile:\n",
    "        doc = nlp(line)\n",
    "        icd = {'Date':'', 'Airline':'', 'Flight':'', 'Location':'', 'Text':''}\n",
    "        for ent in doc.ents:\n",
    "            if ent.text.strip() == '': continue     # skip empty strings\n",
    "            if ent.label_ == u'DATE':               # Get the date\n",
    "                icd['Date'] = ent.text\n",
    "            elif ent.label_ == u'ORG':              # Get the organization\n",
    "                icd['Airline'] = ent.text                \n",
    "            elif ent.label_ == u'PRODUCT':          # Get the flight number\n",
    "                if re.search(r'flight', ent.text, re.I):\n",
    "                    icd['Flight'] = ent.text\n",
    "            elif ent.label_ == u'GPE':              # Get the location\n",
    "                if icd['Location'] == '':\n",
    "                    icd['Location'] = ent.text\n",
    "                else:\n",
    "                    icd['Location'] += ', ' + ent.text\n",
    "        icd['Text'] = line\n",
    "        incidents.append(icd)\n",
    "\n",
    "df = pd.DataFrame(incidents)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2) Reading a new data source\n",
    "Assume that we have came across a new dataset on flight indicents, and we would like to combine this dataset with what we extracted earlier. The first step would be to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Flight #</th>\n",
       "      <th>Route</th>\n",
       "      <th>Type</th>\n",
       "      <th>Registration</th>\n",
       "      <th>cn/In</th>\n",
       "      <th>Aboard</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>08/28/1972</td>\n",
       "      <td>14:30</td>\n",
       "      <td>Papua, New Guinea</td>\n",
       "      <td>Military - Royal Australian Air Force</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lae - Port Moresby</td>\n",
       "      <td>de Havilland Canada DHC-4 Caribou</td>\n",
       "      <td>A4-233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>While traveling through a valley, the pilot re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>06/24/1929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Paul, Minnesota</td>\n",
       "      <td>Northwest Orient Airlines</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Paul - Minneapolis</td>\n",
       "      <td>Ford 5-AT-B Tri-Motor</td>\n",
       "      <td>NC7416</td>\n",
       "      <td>5-AT-002</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Crashed near Indian Mounds park shortly after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>12/23/1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Near Madrid, Spain</td>\n",
       "      <td>Iberia Airlines</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Madrid - Barcelona</td>\n",
       "      <td>Douglas DC-3 (C-47-DL)</td>\n",
       "      <td>EC-ABK</td>\n",
       "      <td>4256</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Crashed into Pandols Mountain while en route.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time             Location  \\\n",
       "2584  08/28/1972  14:30    Papua, New Guinea   \n",
       "182   06/24/1929    NaN  St. Paul, Minnesota   \n",
       "980   12/23/1948    NaN   Near Madrid, Spain   \n",
       "\n",
       "                                   Operator Flight #                   Route  \\\n",
       "2584  Military - Royal Australian Air Force      NaN      Lae - Port Moresby   \n",
       "182               Northwest Orient Airlines      NaN  St. Paul - Minneapolis   \n",
       "980                         Iberia Airlines      NaN      Madrid - Barcelona   \n",
       "\n",
       "                                   Type Registration     cn/In Aboard  \\\n",
       "2584  de Havilland Canada DHC-4 Caribou       A4-233       NaN     29   \n",
       "182               Ford 5-AT-B Tri-Motor       NC7416  5-AT-002      8   \n",
       "980              Douglas DC-3 (C-47-DL)       EC-ABK      4256     27   \n",
       "\n",
       "     Fatalities Ground                                            Summary  \n",
       "2584         25      0  While traveling through a valley, the pilot re...  \n",
       "182           1      0  Crashed near Indian Mounds park shortly after ...  \n",
       "980          27      0      Crashed into Pandols Mountain while en route.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_df = pd.read_csv('data/crashes.csv', dtype='str')\n",
    "external_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Schema Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3) Figuring out how the two datasets are related\n",
    "We need to figure out which columns in the new dataset corresponds to the columns in our dataset. Obviously humans can do this manually by reviewing the names assigned to each column as well as looking at the values listed under each column. However, there are many cases in which this task becomes exteremely cumbersome (e.g., when there are many data sources, or when data-sources are found with no proper description). In this part, we demonstrate some technique to automatically find which columns are related to each other.\n",
    "\n",
    "Let's start by creating subset of both datasets where there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.replace(r'^\\s*$', np.nan, regex=True).dropna(axis=0)\n",
    "full_external_df = external_df.replace(r'^\\s*$', np.nan, regex=True).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4) Using Jaccard similarity to match the columns\n",
    "It is safe to say that columns that share similar values are of the same type. To measure the similarity of the values that appear in two columns, we can use the jaccard similarity. Let's start by computing the similarity of all columns in the external data with the column 'Airline' in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator has similarity score 0.04017857142857143\n",
      "Type has similarity score 0.006361323155216285\n"
     ]
    }
   ],
   "source": [
    "col_vals = set(full_df['Airline'].unique())\n",
    "for col in full_external_df.columns:\n",
    "    ext_col_vals = set(full_external_df[col].unique())\n",
    "    intersection_size = len(col_vals.intersection(ext_col_vals))\n",
    "    union_size = len(col_vals.union(ext_col_vals))\n",
    "    jaccard = intersection_size / union_size\n",
    "    if jaccard != 0:\n",
    "        print(col + ' has similarity score ' + str(jaccard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the same technique for column 'Date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight # has similarity score 0.0037209302325581397\n",
      "cn/In has similarity score 0.0022488755622188904\n",
      "Aboard has similarity score 0.0015923566878980893\n",
      "Fatalities has similarity score 0.001694915254237288\n"
     ]
    }
   ],
   "source": [
    "col_vals = set(full_df['Date'].unique())\n",
    "for col in full_external_df.columns:\n",
    "    ext_col_vals = set(full_external_df[col].unique())\n",
    "    intersection_size = len(col_vals.intersection(ext_col_vals))\n",
    "    union_size = len(col_vals.union(ext_col_vals))\n",
    "    jaccard = intersection_size / union_size\n",
    "    if jaccard != 0:\n",
    "        print(col + ' has similarity score ' + str(jaccard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the jaccard similarity works well when we deal with categorical features which are limited to a fixed set of values. However, for attributes such as 'Date', we can see that jaccard similarity is not performing well. This is because Dates while having similar format can have many distinct values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5) Using FlexMatcher to match the schemas\n",
    "FlexMatcher is package that uses maching learning technqiues to figure out which columns should be mapped together. For instance, while the extact values under column 'Date' may not be identical, FlexMatcher can detect the common patterns and map the column to another column that exhibits similar patterns.\n",
    "\n",
    "FlexMatcher works as follows. It takes as input a list of dataframes and list of dictionaries that describe how the columns in the input dataframes map to the columns that we are interested in. Once this data is provided, FlexMatcher learns the common patterns. Then, we provide a new dataframe and the FlexMatcher would predict which columns of the new dataset are related to the columns we are interested in. \n",
    "\n",
    "Since, we only have two dataframes, we need to simplify our setting. We use our extracted datset to both train on, and the columns we are interested in are exactly the 5 columns that are in the extracted datset. Then, we ask FlexMatcher to make a prediction about the external datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create training data ...\n",
      "Training data done ...\n",
      "0.13944482803344727\n",
      "0.15560221672058105\n",
      "0.629662036895752\n",
      "0.5134270191192627\n",
      "0.36774110794067383\n",
      "0.39583897590637207\n",
      "0.3585529327392578\n",
      "Meta: 0.13860297203063965\n"
     ]
    }
   ],
   "source": [
    "import flexmatcher\n",
    "\n",
    "# training FlexMatcher\n",
    "schema_list = [full_df]\n",
    "mapping_list = [dict(zip(full_df.columns, full_df.columns))]\n",
    "fm = flexmatcher.FlexMatcher(schema_list, mapping_list, sample_size=500)\n",
    "fm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Date',\n",
       " 'Location': 'Location',\n",
       " 'Operator': 'Flight',\n",
       " 'Summary': 'Text',\n",
       " 'Type': 'Airline'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a prediction\n",
    "predicted_mapping = fm.make_prediction(full_external_df)\n",
    "predicted_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to remember that machine learning techniques also make mistakes. In this case, FlexMatcher fails to make a correct prediction for the attribute 'Flight' which should clearly be mapped to column 'Flight #'. It's easy to see why FlexMatcher is confused. The values under 'Flight' in mostly contain the word \"Flight\" in them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1087     Flight 17\n",
       "258     Flight 121\n",
       "58        Flight 2\n",
       "Name: Flight, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['Flight'].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the external datset only list numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5108    778\n",
       "3336    350\n",
       "431     15A\n",
       "Name: Flight #, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_external_df['Flight #'].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it for the learning algorithm to see the similarities. In fact, the algorithm sees more similarities between the 'Flight #' column and other column such as 'Aboard' which represents the number of people on the flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Create a copy of the external_df and remove the column 'Location' from it. Now use FlexMatcher to make a prediction for this new dataframe. How is the new mapping different from the previous mapping? How do you explain the new results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Date',\n",
       " 'Operator': 'Airline',\n",
       " 'Route': 'Location',\n",
       " 'Summary': 'Text',\n",
       " 'Type': 'Flight'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# >>>> to be done by students...\n",
    "new_external_df = external_df.drop(['Location'], axis=1)\n",
    "predicted_mapping = fm.make_prediction(new_external_df)\n",
    "predicted_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entity Linking\n",
    "\n",
    "Now that we know how the columns of the two datasets are related, we can try to merge the two datasets. Our goal is to augment our dataset which additional features that we can find in the external data source. We assume two datapoints refer to the same incident if the listed Airline and the flight number are identical. \n",
    "\n",
    "#### Step 6) Finding matching attributes using dataframes\n",
    "Recall that there is a mistmatch between the format of the flight numbers. We start by cleaning the flight number in our dataset to only keep the numbers (and drop the word flight). Then we can use dataframes to find matching incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "clean_df = full_df.copy()\n",
    "clean_df['Flight'] = clean_df['Flight'].apply(lambda x: '-'.join(re.findall(r'\\d+', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 32 matching records!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_x</th>\n",
       "      <th>Flight</th>\n",
       "      <th>Location_x</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date_y</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location_y</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Flight #</th>\n",
       "      <th>Route</th>\n",
       "      <th>Type</th>\n",
       "      <th>Registration</th>\n",
       "      <th>cn/In</th>\n",
       "      <th>Aboard</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>January 14, 1936, American Airlines Flight 1, ...</td>\n",
       "      <td>01/14/1936</td>\n",
       "      <td>19:32</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark, NJ - Fort Worth, TX</td>\n",
       "      <td>Douglas DC-2-120</td>\n",
       "      <td>NC14274</td>\n",
       "      <td>1307</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Flew into trees and disintegrated. The cause o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>January 14, 1936, American Airlines Flight 1, ...</td>\n",
       "      <td>10/30/1941</td>\n",
       "      <td>22:10</td>\n",
       "      <td>St. Thomas, Ontario, Canada</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>New York - Buffalo - Chicago - Detroit</td>\n",
       "      <td>Douglas DC-3</td>\n",
       "      <td>NC25663</td>\n",
       "      <td>2207</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>The aircraft, on a flight from New York to Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>January 14, 1936, American Airlines Flight 1, ...</td>\n",
       "      <td>03/01/1962</td>\n",
       "      <td>10:09</td>\n",
       "      <td>Jamaica Bay, New York, New York</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>New York City - Los Angeles</td>\n",
       "      <td>Boeing B-707-123B</td>\n",
       "      <td>N7506A</td>\n",
       "      <td>17633/12</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>After taking off from Idlewild Airport and rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Airline            Date_x Flight         Location_x  \\\n",
       "0  American Airlines  January 14, 1936      1  Goodwin, Arkansas   \n",
       "1  American Airlines  January 14, 1936      1  Goodwin, Arkansas   \n",
       "2  American Airlines  January 14, 1936      1  Goodwin, Arkansas   \n",
       "\n",
       "                                                Text      Date_y   Time  \\\n",
       "0  January 14, 1936, American Airlines Flight 1, ...  01/14/1936  19:32   \n",
       "1  January 14, 1936, American Airlines Flight 1, ...  10/30/1941  22:10   \n",
       "2  January 14, 1936, American Airlines Flight 1, ...  03/01/1962  10:09   \n",
       "\n",
       "                        Location_y           Operator Flight #  \\\n",
       "0                Goodwin, Arkansas  American Airlines        1   \n",
       "1      St. Thomas, Ontario, Canada  American Airlines        1   \n",
       "2  Jamaica Bay, New York, New York  American Airlines        1   \n",
       "\n",
       "                                    Route               Type Registration  \\\n",
       "0             Newark, NJ - Fort Worth, TX   Douglas DC-2-120      NC14274   \n",
       "1  New York - Buffalo - Chicago - Detroit       Douglas DC-3      NC25663   \n",
       "2             New York City - Los Angeles  Boeing B-707-123B       N7506A   \n",
       "\n",
       "      cn/In Aboard Fatalities Ground  \\\n",
       "0      1307     17         17      0   \n",
       "1      2207     20         20      0   \n",
       "2  17633/12     95         95      0   \n",
       "\n",
       "                                             Summary  \n",
       "0  Flew into trees and disintegrated. The cause o...  \n",
       "1  The aircraft, on a flight from New York to Chi...  \n",
       "2  After taking off from Idlewild Airport and rea...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = clean_df.merge(full_external_df,\n",
    "                         right_on=['Operator', 'Flight #'],\n",
    "                         left_on=['Airline', 'Flight'], how='inner')\n",
    "print('We have found ' + str(len(combined)) + ' matching records!')\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, but is that all?\n",
    "\n",
    "#### Step 7) Trying approximate string matching using the py_stringsimjoin package\n",
    "The main problem with an exact match is that there might be slight variations of airline names. For instance, XXX and YYY both refer to the same airline but an exact match would miss that. To solve this issue, we can match two airline names that are almost similar. For instance, we can compute the edit distance between the two records and keep the records have a small distance (say at most 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import py_stringsimjoin as ssj\n",
    "\n",
    "# The py_stringsimjoin package requires the dataframe to have a column\n",
    "# that can serve as a unique key. The next two lines add a column 'id'\n",
    "# to each dataframe to address this.\n",
    "clean_df['id'] = range(len(clean_df))\n",
    "full_external_df['id'] = range(len(full_external_df))\n",
    "\n",
    "# The inputs are:\n",
    "# (1-2) left table and the right table, (3-4) the unique key in the left table and the right table,\n",
    "# (5-6) the attribute to join on in the left table and the right table,\n",
    "# (7-8) list of attributes to fetch from the left table and the right table,\n",
    "# (9) the threshold for the edit distance; values with smaller edit distance would be considered a match.\n",
    "similar_airlines = ssj.edit_distance_join(clean_df, full_external_df, 'id', 'id', 'Airline','Operator',\n",
    "                                          l_out_attrs=['Airline', 'Date', 'Location', 'Flight'],\n",
    "                                          r_out_attrs=['Operator', 'Flight #', 'Location', 'Fatalities'],\n",
    "                                          threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script only joins the airline name and does not take into account the flight numbers. To get the desired resutls, we can only select those rows that have matching flight numbers. Note that the join function appends the prefix 'r_' and 'l_' to the columns of the right and the left table respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 41 matching records!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "      <th>l_Airline</th>\n",
       "      <th>l_Date</th>\n",
       "      <th>l_Location</th>\n",
       "      <th>l_Flight</th>\n",
       "      <th>r_Operator</th>\n",
       "      <th>r_Flight #</th>\n",
       "      <th>r_Location</th>\n",
       "      <th>r_Fatalities</th>\n",
       "      <th>_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>597</td>\n",
       "      <td>269</td>\n",
       "      <td>664</td>\n",
       "      <td>American Eagle</td>\n",
       "      <td>October 31, 1994,</td>\n",
       "      <td>Roselawn, Indiana, Chicago</td>\n",
       "      <td>4184</td>\n",
       "      <td>American Eagle</td>\n",
       "      <td>4184</td>\n",
       "      <td>Roselawn, Indiana</td>\n",
       "      <td>68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>491</td>\n",
       "      <td>200</td>\n",
       "      <td>513</td>\n",
       "      <td>Aeroflot</td>\n",
       "      <td>October 11, 1984</td>\n",
       "      <td>Tupolev, Omsk, Russia</td>\n",
       "      <td>3352</td>\n",
       "      <td>Aeroflot</td>\n",
       "      <td>3352</td>\n",
       "      <td>Near Omsk, Russia</td>\n",
       "      <td>174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>160</td>\n",
       "      <td>444</td>\n",
       "      <td>Aeroflot</td>\n",
       "      <td>January 13, 1977,</td>\n",
       "      <td>Tupolev, Tu-104</td>\n",
       "      <td>3843</td>\n",
       "      <td>Aeroflot</td>\n",
       "      <td>3843</td>\n",
       "      <td>Near Alma Ata,  Kazakastan, USSR</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id  l_id  r_id       l_Airline             l_Date  \\\n",
       "597  597   269   664  American Eagle  October 31, 1994,   \n",
       "491  491   200   513        Aeroflot   October 11, 1984   \n",
       "405  405   160   444        Aeroflot  January 13, 1977,   \n",
       "\n",
       "                     l_Location l_Flight      r_Operator r_Flight #  \\\n",
       "597  Roselawn, Indiana, Chicago     4184  American Eagle       4184   \n",
       "491       Tupolev, Omsk, Russia     3352        Aeroflot       3352   \n",
       "405             Tupolev, Tu-104     3843        Aeroflot       3843   \n",
       "\n",
       "                           r_Location r_Fatalities  _sim_score  \n",
       "597                 Roselawn, Indiana           68         0.0  \n",
       "491                 Near Omsk, Russia          174         0.0  \n",
       "405  Near Alma Ata,  Kazakastan, USSR           96         0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting those rows with matching flight numbers\n",
    "combined = similar_airlines.loc[similar_airlines['r_Flight #'] == similar_airlines['l_Flight']]\n",
    "print('We have found ' + str(len(combined)) + ' matching records!')\n",
    "combined.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improvement over our previous results. We can take a look at rows in which the airline names don't exactly match to see the new matches that we have detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_Airline</th>\n",
       "      <th>r_Operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Japan Airlines</td>\n",
       "      <td>Japan Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Japan Airlines</td>\n",
       "      <td>Japan Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Pacific Southwest Airlines</td>\n",
       "      <td>PacifiSouthwest Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>PMTair</td>\n",
       "      <td>PMT Air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      l_Airline                r_Operator\n",
       "124             United Airlines          United Air Lines\n",
       "137             United Airlines          United Air Lines\n",
       "145             United Airlines          United Air Lines\n",
       "168             United Airlines          United Air Lines\n",
       "354              Japan Airlines           Japan Air Lines\n",
       "420             United Airlines          United Air Lines\n",
       "446              Japan Airlines           Japan Air Lines\n",
       "516  Pacific Southwest Airlines  PacifiSouthwest Airlines\n",
       "764                      PMTair                   PMT Air"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc[combined['l_Airline'] != combined['r_Operator'], ['l_Airline', 'r_Operator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8) Linking the entities using other columns\n",
    "\n",
    "What we have presented so far is by no means the best way we can approach the problem of linking entities. We only focused on a subset of columns to see what techniques can be applied.\n",
    "\n",
    "An alternative approach to linking these entities would be to use the Date column in both datasets. This probably yields better results since (1) it's quite unlikely to have multiple incidents in a day, and (2) it's easier to check for an exact match. We need to consider the fact that Date format is different in the two datasets, but after cleaning the data, it might be the most useful column for matching the entities. \n",
    "\n",
    "**Task: Use the column 'Date' to find the matching between the two datasets. Note that attribute 'Date' is usually not missing, thus we can find more matches by considering all data points (even those with missing values in different columns).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>> to be done by students...\n",
    "\n",
    "# use column 'Date' in df and external_df to find a matching incidents\n",
    "# sub-step 1) Transform the Date in df to have the same format as the other dataset\n",
    "# sub-step 2) Use dataframe's merge function to find an exact match\n",
    "# sub-setp 3) Sample a few rows from the resulting table and see how many seems to be correct/incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
