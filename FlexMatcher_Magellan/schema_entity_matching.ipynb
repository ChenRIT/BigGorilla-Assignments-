{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema Matching & Entity Linking\n",
    "#### Step 1) Loading our extracted data!\n",
    "Here, we are repeating the last step of the first tutorial to create a data-frame containing the features that we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date</th>\n",
       "      <th>Flight</th>\n",
       "      <th>Location</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td></td>\n",
       "      <td>November 23, 1961</td>\n",
       "      <td>Aerolíneas Argentinas Flight</td>\n",
       "      <td>a de Havilland Comet, Campinas, Brazil</td>\n",
       "      <td>November 23, 1961, Aerolíneas Argentinas Fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Luxair</td>\n",
       "      <td>November 6, 2002</td>\n",
       "      <td>Flight 9642</td>\n",
       "      <td>Fokker F50</td>\n",
       "      <td>November 6, 2002, Luxair Flight 9642, a Fokker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Boeing</td>\n",
       "      <td>February 3, 2005</td>\n",
       "      <td></td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>February 3, 2005, Kam Air Flight 904, a Boeing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Airline               Date                        Flight  \\\n",
       "235          November 23, 1961  Aerolíneas Argentinas Flight   \n",
       "886  Luxair   November 6, 2002                   Flight 9642   \n",
       "909  Boeing   February 3, 2005                                 \n",
       "\n",
       "                                   Location  \\\n",
       "235  a de Havilland Comet, Campinas, Brazil   \n",
       "886                              Fokker F50   \n",
       "909                             Afghanistan   \n",
       "\n",
       "                                                  Text  \n",
       "235  November 23, 1961, Aerolíneas Argentinas Fligh...  \n",
       "886  November 6, 2002, Luxair Flight 9642, a Fokker...  \n",
       "909  February 3, 2005, Kam Air Flight 904, a Boeing...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "incidents = []\n",
    "with open('./data/aviation_incidents_cleaned.txt') as myfile:\n",
    "    for line in myfile:\n",
    "        doc = nlp(line)\n",
    "        icd = {'Date':'', 'Airline':'', 'Flight':'', 'Location':'', 'Text':''}\n",
    "        for ent in doc.ents:\n",
    "            if ent.text.strip() == '': continue     # skip empty strings\n",
    "            if ent.label_ == u'DATE':               # Get the date\n",
    "                icd['Date'] = ent.text\n",
    "            elif ent.label_ == u'ORG':              # Get the organization\n",
    "                icd['Airline'] = ent.text                \n",
    "            elif ent.label_ == u'PRODUCT':          # Get the flight number\n",
    "                if re.search(r'flight', ent.text, re.I):\n",
    "                    icd['Flight'] = ent.text\n",
    "            elif ent.label_ == u'GPE':              # Get the location\n",
    "                if icd['Location'] == '':\n",
    "                    icd['Location'] = ent.text\n",
    "                else:\n",
    "                    icd['Location'] += ', ' + ent.text\n",
    "        icd['Text'] = line\n",
    "        incidents.append(icd)\n",
    "\n",
    "df = pd.DataFrame(incidents)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2) Reading a new data source\n",
    "Assume that we have came across a new dataset on flight indicents, and we would like to combine this dataset with what we extracted earlier. The first step would be to read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Flight #</th>\n",
       "      <th>Route</th>\n",
       "      <th>Type</th>\n",
       "      <th>Registration</th>\n",
       "      <th>cn/In</th>\n",
       "      <th>Aboard</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>09/30/1973</td>\n",
       "      <td>20:40</td>\n",
       "      <td>Near Sverdlovsk, Russia</td>\n",
       "      <td>Aeroflot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tupolev TU-104B</td>\n",
       "      <td>CCCP-42506</td>\n",
       "      <td>21904</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>The aircraft crashed shortly after takeoff whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>10/29/1973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sainte Lucia Island</td>\n",
       "      <td>CATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Britten-Norman BN-2A-6 Islander</td>\n",
       "      <td>N37JA</td>\n",
       "      <td>210</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Flew into Mt. Gimie while en route.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4556</th>\n",
       "      <td>04/20/1998</td>\n",
       "      <td>16:47</td>\n",
       "      <td>Near Bogota, Colombia</td>\n",
       "      <td>Air France</td>\n",
       "      <td>422</td>\n",
       "      <td>Bogota - Quito</td>\n",
       "      <td>Boeing B-727-230</td>\n",
       "      <td>HC-BSU</td>\n",
       "      <td>21622/1431</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>The aircraft, leased from TAME, crashed atop f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time                 Location    Operator Flight #  \\\n",
       "2686  09/30/1973  20:40  Near Sverdlovsk, Russia    Aeroflot      NaN   \n",
       "2690  10/29/1973    NaN      Sainte Lucia Island        CATA      NaN   \n",
       "4556  04/20/1998  16:47    Near Bogota, Colombia  Air France      422   \n",
       "\n",
       "               Route                             Type Registration  \\\n",
       "2686             NaN                  Tupolev TU-104B   CCCP-42506   \n",
       "2690             NaN  Britten-Norman BN-2A-6 Islander        N37JA   \n",
       "4556  Bogota - Quito                 Boeing B-727-230       HC-BSU   \n",
       "\n",
       "           cn/In Aboard Fatalities Ground  \\\n",
       "2686       21904    108        108      0   \n",
       "2690         210      4          4      0   \n",
       "4556  21622/1431     53         53      0   \n",
       "\n",
       "                                                Summary  \n",
       "2686  The aircraft crashed shortly after takeoff whi...  \n",
       "2690                Flew into Mt. Gimie while en route.  \n",
       "4556  The aircraft, leased from TAME, crashed atop f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_df = pd.read_csv('data/crashes.csv', dtype='str')\n",
    "external_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Schema Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3) Figuring out how the two datasets are related\n",
    "We need to figure out which columns in the new dataset corresponds to the columns in our dataset. Obviously humans can do this manually by reviewing the names assigned to each column as well as looking at the values listed under each column. However, there are many cases in which this task becomes exteremely cumbersome (e.g., when there are many data sources, or when data-sources are found with no proper description). In this part, we demonstrate some technique to automatically find which columns are related to each other.\n",
    "\n",
    "Let's start by creating subset of both datasets where there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = df.replace(r'^\\s*$', np.nan, regex=True).dropna(axis=0)\n",
    "full_external_df = external_df.replace(r'^\\s*$', np.nan, regex=True).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n",
      "944\n"
     ]
    }
   ],
   "source": [
    "print(len(full_df))\n",
    "print(len(full_external_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4) Using Jaccard similarity to match the columns\n",
    "It is safe to say that columns that share similar values are of the same type. To measure the similarity of the values that appear in two columns, we can use the jaccard similarity. Let's start by computing the similarity of all columns in the external data with the column 'Airline' in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator has similarity score 0.04017857142857143\n",
      "Type has similarity score 0.006361323155216285\n"
     ]
    }
   ],
   "source": [
    "col_vals = set(full_df['Airline'].unique())\n",
    "for col in full_external_df.columns:\n",
    "    ext_col_vals = set(full_external_df[col].unique())\n",
    "    intersection_size = len(col_vals.intersection(ext_col_vals))\n",
    "    union_size = len(col_vals.union(ext_col_vals))\n",
    "    jaccard = intersection_size / union_size\n",
    "    if jaccard != 0:\n",
    "        print(col + ' has similarity score ' + str(jaccard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the same technique for column 'Date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flight # has similarity score 0.0037209302325581397\n",
      "cn/In has similarity score 0.0022488755622188904\n",
      "Aboard has similarity score 0.0015923566878980893\n",
      "Fatalities has similarity score 0.001694915254237288\n"
     ]
    }
   ],
   "source": [
    "col_vals = set(full_df['Date'].unique())\n",
    "for col in full_external_df.columns:\n",
    "    ext_col_vals = set(full_external_df[col].unique())\n",
    "    intersection_size = len(col_vals.intersection(ext_col_vals))\n",
    "    union_size = len(col_vals.union(ext_col_vals))\n",
    "    jaccard = intersection_size / union_size\n",
    "    if jaccard != 0:\n",
    "        print(col + ' has similarity score ' + str(jaccard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the jaccard similarity works well when we deal with categorical features which are limited to a fixed set of values. However, for attributes such as 'Date', we can see that jaccard similarity is not performing well. This is because Dates while having similar format can have many distinct values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5) Using FlexMatcher to match the schemas\n",
    "FlexMatcher is package that uses maching learning technqiues to figure out which columns should be mapped together. For instance, while the extact values under column 'Date' may not be identical, FlexMatcher can detect the common patterns and map the column to another column that exhibits similar patterns.\n",
    "\n",
    "FlexMatcher works as follows. It takes as input a list of dataframes and list of dictionaries that describe how the columns in the input dataframes map to the columns that we are interested in. Once this data is provided, FlexMatcher learns the common patterns. Then, we provide a new dataframe and the FlexMatcher would predict which columns of the new dataset are related to the columns we are interested in. \n",
    "\n",
    "Since, we only have two dataframes, we need to simplify our setting. We use our extracted datset to both train on, and the columns we are interested in are exactly the 5 columns that are in the extracted datset. Then, we ask FlexMatcher to make a prediction about the external datasource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up FlexMatcher ...\n",
      "Creating Tranining Data ...\n"
     ]
    }
   ],
   "source": [
    "import flexmatcher\n",
    "\n",
    "# training FlexMatcher\n",
    "schema_list = [full_df]\n",
    "mapping_list = [dict(zip(full_df.columns, full_df.columns))]\n",
    "fm = flexmatcher.FlexMatcher()\n",
    "fm.train(schema_list, mapping_list, sample_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Airline': 'Airline',\n",
       " 'Date': 'Date',\n",
       " 'Flight': 'Flight',\n",
       " 'Location': 'Location',\n",
       " 'Text': 'Text'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date ==== Flight\n",
      "Location ==== Location\n",
      "Operator ==== Airline\n",
      "cn/In ==== Date\n",
      "Summary ==== Text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/behzad/miniconda2/envs/py3flex/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# making a prediction\n",
    "predicted_mapping = fm.predict(full_external_df, predict_all=False)\n",
    "for t, v in predicted_mapping.items():\n",
    "    print(t, '====', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to remember that machine learning techniques also make mistakes. In this case, FlexMatcher fails to make a correct prediction for the attribute 'Flight' which should clearly be mapped to column 'Flight #'. It's easy to see why FlexMatcher is confused. The values under 'Flight' in mostly contain the word \"Flight\" in them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428              Flight 440\n",
       "1091         AirAsia Flight\n",
       "511     Air Rhodesia Flight\n",
       "Name: Flight, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['Flight'].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the external datset only list numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4789     352\n",
       "4040    2574\n",
       "2694     160\n",
       "Name: Flight #, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_external_df['Flight #'].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes it for the learning algorithm to see the similarities. In fact, the algorithm sees more similarities between the 'Flight #' column and other column such as 'Aboard' which represents the number of people on the flight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Entity Linking\n",
    "\n",
    "Now that we know how the columns of the two datasets are related, we can try to merge the two datasets. Our goal is to augment our dataset which additional features that we can find in the external data source. We assume two datapoints refer to the same incident if the listed Airline and the flight number are identical. \n",
    "\n",
    "#### Step 6) Finding matching attributes using dataframes\n",
    "Recall that there is a mistmatch between the format of the flight numbers. We start by cleaning the flight number in our dataset to only keep the numbers (and drop the word flight). Then we can use dataframes to find matching incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "clean_df = full_df.copy()\n",
    "clean_df['Flight'] = clean_df['Flight'].apply(lambda x: '-'.join(re.findall(r'\\d+', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 32 matching records!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_x</th>\n",
       "      <th>Flight</th>\n",
       "      <th>Location_x</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date_y</th>\n",
       "      <th>Time</th>\n",
       "      <th>Location_y</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Flight #</th>\n",
       "      <th>Route</th>\n",
       "      <th>Type</th>\n",
       "      <th>Registration</th>\n",
       "      <th>cn/In</th>\n",
       "      <th>Aboard</th>\n",
       "      <th>Fatalities</th>\n",
       "      <th>Ground</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>January 14, 1936, American Airlines Flight 1, ...</td>\n",
       "      <td>01/14/1936</td>\n",
       "      <td>19:32</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>Newark, NJ - Fort Worth, TX</td>\n",
       "      <td>Douglas DC-2-120</td>\n",
       "      <td>NC14274</td>\n",
       "      <td>1307</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>Flew into trees and disintegrated. The cause o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>January 14, 1936, American Airlines Flight 1, ...</td>\n",
       "      <td>10/30/1941</td>\n",
       "      <td>22:10</td>\n",
       "      <td>St. Thomas, Ontario, Canada</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>New York - Buffalo - Chicago - Detroit</td>\n",
       "      <td>Douglas DC-3</td>\n",
       "      <td>NC25663</td>\n",
       "      <td>2207</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>The aircraft, on a flight from New York to Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>January 14, 1936, American Airlines Flight 1, ...</td>\n",
       "      <td>03/01/1962</td>\n",
       "      <td>10:09</td>\n",
       "      <td>Jamaica Bay, New York, New York</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>New York City - Los Angeles</td>\n",
       "      <td>Boeing B-707-123B</td>\n",
       "      <td>N7506A</td>\n",
       "      <td>17633/12</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>After taking off from Idlewild Airport and rea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Airline            Date_x Flight         Location_x  \\\n",
       "0  American Airlines  January 14, 1936      1  Goodwin, Arkansas   \n",
       "1  American Airlines  January 14, 1936      1  Goodwin, Arkansas   \n",
       "2  American Airlines  January 14, 1936      1  Goodwin, Arkansas   \n",
       "\n",
       "                                                Text      Date_y   Time  \\\n",
       "0  January 14, 1936, American Airlines Flight 1, ...  01/14/1936  19:32   \n",
       "1  January 14, 1936, American Airlines Flight 1, ...  10/30/1941  22:10   \n",
       "2  January 14, 1936, American Airlines Flight 1, ...  03/01/1962  10:09   \n",
       "\n",
       "                        Location_y           Operator Flight #  \\\n",
       "0                Goodwin, Arkansas  American Airlines        1   \n",
       "1      St. Thomas, Ontario, Canada  American Airlines        1   \n",
       "2  Jamaica Bay, New York, New York  American Airlines        1   \n",
       "\n",
       "                                    Route               Type Registration  \\\n",
       "0             Newark, NJ - Fort Worth, TX   Douglas DC-2-120      NC14274   \n",
       "1  New York - Buffalo - Chicago - Detroit       Douglas DC-3      NC25663   \n",
       "2             New York City - Los Angeles  Boeing B-707-123B       N7506A   \n",
       "\n",
       "      cn/In Aboard Fatalities Ground  \\\n",
       "0      1307     17         17      0   \n",
       "1      2207     20         20      0   \n",
       "2  17633/12     95         95      0   \n",
       "\n",
       "                                             Summary  \n",
       "0  Flew into trees and disintegrated. The cause o...  \n",
       "1  The aircraft, on a flight from New York to Chi...  \n",
       "2  After taking off from Idlewild Airport and rea...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = clean_df.merge(full_external_df,\n",
    "                         right_on=['Operator', 'Flight #'],\n",
    "                         left_on=['Airline', 'Flight'], how='inner')\n",
    "print('We have found ' + str(len(combined)) + ' matching records!')\n",
    "combined.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, but is that all?\n",
    "\n",
    "#### Step 7) Trying approximate string matching using the py_stringsimjoin package\n",
    "The main problem with an exact match is that there might be slight variations of airline names. For instance, XXX and YYY both refer to the same airline but an exact match would miss that. To solve this issue, we can match two airline names that are almost similar. For instance, we can compute the edit distance between the two records and keep the records have a small distance (say at most 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import py_stringsimjoin as ssj\n",
    "\n",
    "# The py_stringsimjoin package requires the dataframe to have a column\n",
    "# that can serve as a unique key. The next two lines add a column 'id'\n",
    "# to each dataframe to address this.\n",
    "clean_df['id'] = range(len(clean_df))\n",
    "full_external_df['id'] = range(len(full_external_df))\n",
    "\n",
    "# The inputs are:\n",
    "# (1-2) left table and the right table, (3-4) the unique key in the left table and the right table,\n",
    "# (5-6) the attribute to join on in the left table and the right table,\n",
    "# (7-8) list of attributes to fetch from the left table and the right table,\n",
    "# (9) the threshold for the edit distance; values with smaller edit distance would be considered a match.\n",
    "similar_airlines = ssj.edit_distance_join(clean_df, full_external_df, 'id', 'id', 'Airline','Operator',\n",
    "                                          l_out_attrs=['Airline', 'Date', 'Location', 'Flight'],\n",
    "                                          r_out_attrs=['Operator', 'Flight #', 'Location', 'Fatalities'],\n",
    "                                          threshold=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script only joins the airline name and does not take into account the flight numbers. To get the desired resutls, we can only select those rows that have matching flight numbers. Note that the join function appends the prefix 'r_' and 'l_' to the columns of the right and the left table respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found 41 matching records!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>l_id</th>\n",
       "      <th>r_id</th>\n",
       "      <th>l_Airline</th>\n",
       "      <th>l_Date</th>\n",
       "      <th>l_Location</th>\n",
       "      <th>l_Flight</th>\n",
       "      <th>r_Operator</th>\n",
       "      <th>r_Flight #</th>\n",
       "      <th>r_Location</th>\n",
       "      <th>r_Fatalities</th>\n",
       "      <th>_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>66</td>\n",
       "      <td>229</td>\n",
       "      <td>Caledonian Airways</td>\n",
       "      <td>March 4, 1962,</td>\n",
       "      <td>Douala</td>\n",
       "      <td>153</td>\n",
       "      <td>Caledonian Airways</td>\n",
       "      <td>153</td>\n",
       "      <td>Douala, Cameroon</td>\n",
       "      <td>111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>19</td>\n",
       "      <td>78</td>\n",
       "      <td>United Airlines</td>\n",
       "      <td>October 24, 1947</td>\n",
       "      <td>Utah, United States</td>\n",
       "      <td>608</td>\n",
       "      <td>United Air Lines</td>\n",
       "      <td>608</td>\n",
       "      <td>Bryce Canyon, Utah</td>\n",
       "      <td>53</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>January 14, 1936</td>\n",
       "      <td>Goodwin, Arkansas</td>\n",
       "      <td>1</td>\n",
       "      <td>American Airlines</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica Bay, New York, New York</td>\n",
       "      <td>95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id  l_id  r_id           l_Airline            l_Date  \\\n",
       "277  277    66   229  Caledonian Airways    March 4, 1962,   \n",
       "137  137    19    78     United Airlines  October 24, 1947   \n",
       "272  272     1   228   American Airlines  January 14, 1936   \n",
       "\n",
       "              l_Location l_Flight          r_Operator r_Flight #  \\\n",
       "277               Douala      153  Caledonian Airways        153   \n",
       "137  Utah, United States      608    United Air Lines        608   \n",
       "272    Goodwin, Arkansas        1   American Airlines          1   \n",
       "\n",
       "                          r_Location r_Fatalities  _sim_score  \n",
       "277                 Douala, Cameroon          111         0.0  \n",
       "137               Bryce Canyon, Utah           53         2.0  \n",
       "272  Jamaica Bay, New York, New York           95         0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting those rows with matching flight numbers\n",
    "combined = similar_airlines.loc[similar_airlines['r_Flight #'] == similar_airlines['l_Flight']]\n",
    "print('We have found ' + str(len(combined)) + ' matching records!')\n",
    "combined.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improvement over our previous results. We can take a look at rows in which the airline names don't exactly match to see the new matches that we have detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l_Airline</th>\n",
       "      <th>r_Operator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Japan Airlines</td>\n",
       "      <td>Japan Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>United Airlines</td>\n",
       "      <td>United Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Japan Airlines</td>\n",
       "      <td>Japan Air Lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Pacific Southwest Airlines</td>\n",
       "      <td>PacifiSouthwest Airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>PMTair</td>\n",
       "      <td>PMT Air</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      l_Airline                r_Operator\n",
       "124             United Airlines          United Air Lines\n",
       "137             United Airlines          United Air Lines\n",
       "145             United Airlines          United Air Lines\n",
       "168             United Airlines          United Air Lines\n",
       "354              Japan Airlines           Japan Air Lines\n",
       "420             United Airlines          United Air Lines\n",
       "446              Japan Airlines           Japan Air Lines\n",
       "516  Pacific Southwest Airlines  PacifiSouthwest Airlines\n",
       "764                      PMTair                   PMT Air"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.loc[combined['l_Airline'] != combined['r_Operator'], ['l_Airline', 'r_Operator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8) Linking the entities using other columns\n",
    "\n",
    "What we have presented so far is by no means the best way we can approach the problem of linking entities. We only focused on a subset of columns to see what techniques can be applied.\n",
    "\n",
    "An alternative approach to linking these entities would be to use the Date column in both datasets. This probably yields better results since (1) it's quite unlikely to have multiple incidents in a day, and (2) it's easier to check for an exact match. We need to consider the fact that Date format is different in the two datasets, but after cleaning the data, it might be the most useful column for matching the entities. \n",
    "\n",
    "**Task: Use the column 'Date' to find the matching between the two datasets. Note that attribute 'Date' is usually not missing, thus we can find more matches by considering all data points (even those with missing values in different columns).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>> to be done by students...\n",
    "\n",
    "# use column 'Date' in df and external_df to find a matching incidents\n",
    "# sub-step 1) Transform the Date in df to have the same format as the other dataset\n",
    "# sub-step 2) Use dataframe's merge function to find an exact match\n",
    "# sub-setp 3) Sample a few rows from the resulting table and see how many seems to be correct/incorrect"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
