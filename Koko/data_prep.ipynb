{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four parts for each component:\n",
    "1. Introduction\n",
    "2. Example\n",
    "3. Graded assignment\n",
    "\n",
    "How many components?\n",
    "1. Data extraction: web scraping\n",
    "2. Data cleaning: python\n",
    "4. Entity recognition: json output of Koko results\n",
    "5. Data transformation: from json to dataframe\n",
    "\n",
    "Difficulty level:\n",
    "1. From trivial to non-trivial tasks -- this's a graduate course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: extract texts of aviation incidents from websites  \n",
    "Tools: BeautifulSoup, scrapy  \n",
    "Grading metrics: autograder finds a given set of sentences in the txt file uploaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use BeautifulSoup to extract text information from the aircraft incident website.  \n",
    "BeautifulSoup has been pre-installed for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use Python's own html.parser.  \n",
    "You can definitely try other parsers, as illustrated [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'List of accidents and incidents involving commercial aircraft - Wikipedia'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "input_html = \"./data/aircraft_incidents.htm\"\n",
    "with open(input_html, \"r\") as ifile:\n",
    "    soup = BeautifulSoup(ifile, 'lxml')\n",
    "    \n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 1:** Use BeautifulSoup to scrape the website on \\[server url\\], and generate a text file containing all the text on the website. The generated file should not contain any tag information of the scraped html file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here #\n",
    "\n",
    "fname = \"aviation_incidents.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will check if the generated text file satisfy the requirement.\n",
    "(We should have a more strict checking after the assignment is submitted.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "<html></html>\n",
      "Nothing special.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(fname, \"r\") as ifile:\n",
    "    # Check if all tags have been removed\n",
    "    doc = ifile.read()\n",
    "    result = re.search(r\"<.*>\", doc)\n",
    "    if result:\n",
    "        print(\"Error: \\n{}\".format(result.string))\n",
    "    else:\n",
    "        print(\"No tag found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Clean the extracted text file to move years into each line.  \n",
    "Tools: Python  \n",
    "Grading metrics: autograder would check the format of each line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entity recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: extract airlines and aircraft types  \n",
    "Tools: Koko  \n",
    "Grading metrics: autograder would examine the json output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: transform Koko's json output to dataframe  \n",
    "Tools: Python (read_json)  \n",
    "Grading metrics: autograder would load the dataframe and do some checking, e.g., shape.  \n",
    "Comments: is this part too simple?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_test",
   "language": "python",
   "name": "python3_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
